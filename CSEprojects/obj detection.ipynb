{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp38-cp38-win_amd64.whl (162.6 MB)\n",
      "     -------------------------------------- 162.6/162.6 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from torch) (4.4.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\CSEprojects\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images are :  592\n",
      "Validation images are :  148\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import choice\n",
    "import shutil\n",
    "\n",
    "#arrays to store file names\n",
    "imgs =[]\n",
    "xmls =[]\n",
    "\n",
    "#setup dir names\n",
    "trainPath = 'C:\\\\Users\\\\DELL\\\\Desktop\\\\CSEprojects\\\\dataset\\\\images\\\\train'\n",
    "valPath = 'C:\\\\Users\\\\DELL\\\\Desktop\\\\CSEprojects\\\\dataset\\\\images\\\\val'\n",
    "crsPath = 'C:\\\\Users\\\\DELL\\\\Desktop\\\\CSEprojects\\\\ts\\\\ts' #dir where images and annotations stored\n",
    "\n",
    "#setup ratio (val ratio = rest of the files in origin dir after splitting into train and test)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "\n",
    "#total count of imgs\n",
    "totalImgCount = len(os.listdir(crsPath))/2\n",
    "\n",
    "#soring files to corresponding arrays\n",
    "for (dirname, dirs, files) in os.walk(crsPath):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.txt'):\n",
    "            xmls.append(filename)\n",
    "        else:\n",
    "            imgs.append(filename)\n",
    "\n",
    "\n",
    "#counting range for cycles\n",
    "countForTrain = int(len(imgs)*train_ratio)\n",
    "countForVal = int(len(imgs)*val_ratio)\n",
    "print(\"training images are : \",countForTrain)\n",
    "print(\"Validation images are : \",countForVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\Desktop\\\\CSE projects\\\\dataset\\\\images\\\\val\\\\ts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainimagePath = 'C:\\\\Users\\\\DELL\\\\Desktop\\\\CSEprojects\\\\dataset\\\\images\\\\train'\n",
    "trainlabelPath = 'C:\\\\Users\\\\DELL\\\\Desktop\\\\CSEprojects\\\\dataset\\\\labels\\\\train'\n",
    "valimagePath = 'C:\\\\Users\\\\DELL\\\\Desktop\\\\CSEprojects\\\\dataset\\\\images\\\\val'\n",
    "vallabelPath = 'C:\\\\Users\\\\DELL\\\\Desktop\\\\CSEprojects\\\\dataset\\\\labels\\\\val'\n",
    "#cycle for train dir\n",
    "for x in range(countForTrain):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "\n",
    "\n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    xmls.remove(fileXml)\n",
    "\n",
    "\n",
    "\n",
    "#cycle for test dir   \n",
    "for x in range(countForVal):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(valimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(vallabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(crsPath, fileJpg), os.path.join(valimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(crsPath, fileXml), os.path.join(vallabelPath, fileXml))\n",
    "    \n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    xmls.remove(fileXml)\n",
    "\n",
    "#rest of files will be validation files, so rename origin dir to val dir\n",
    "#os.rename(crsPath, valPath)\n",
    "shutil.move(crsPath, valPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] [--weights WEIGHTS] [--cfg CFG] [--data DATA] [--hyp HYP]\n",
      "                [--epochs EPOCHS] [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "                [--rect] [--resume [RESUME]] [--nosave] [--noval]\n",
      "                [--noautoanchor] [--noplots] [--evolve [EVOLVE]]\n",
      "                [--bucket BUCKET] [--cache [CACHE]] [--image-weights]\n",
      "                [--device DEVICE] [--multi-scale] [--single-cls]\n",
      "                [--optimizer {SGD,Adam,AdamW}] [--sync-bn] [--workers WORKERS]\n",
      "                [--project PROJECT] [--name NAME] [--exist-ok] [--quad]\n",
      "                [--cos-lr] [--label-smoothing LABEL_SMOOTHING]\n",
      "                [--patience PATIENCE] [--freeze FREEZE [FREEZE ...]]\n",
      "                [--save-period SAVE_PERIOD] [--seed SEED]\n",
      "                [--local_rank LOCAL_RANK] [--entity ENTITY]\n",
      "                [--upload_dataset [UPLOAD_DATASET]]\n",
      "                [--bbox_interval BBOX_INTERVAL]\n",
      "                [--artifact_alias ARTIFACT_ALIAS]\n",
      "train.py: error: unrecognized arguments: 'C:\\Users\\DELL\\Desktop\\CSEprojects\\dataset\\dataset.yaml'\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 415 --batch 16 --epochs 30 --data= 'C:\\Users\\DELL\\Desktop\\CSEprojects\\dataset\\dataset.yaml' --weights yolov5s.pt --cache"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff3debebb0dc3bfe1beec41c02457615b0fac661ad1faf3393109000304b34ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
